{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from astropy.io import fits\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.wcs import WCS\n",
    "from glob import glob\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Author: Trevor Dorn-Wallenstein\n",
    "# Date: 9/20/17\n",
    "# Note: the data reduction portion of this does almost exactly what acronym (Weisenberger et al. 2017) does, with the exception of performing an overscan subtraction before trimming. I wrote this to be slightly more explicit (read: slower) so that a PreMAP student can run any portion of the reduction and see what it does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = '/Volumes/shoobert/Research/UW/WR_timing/data/9_11_17/ARCTIC/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_hdu = fits.open(data_dir+'wr124_g.0003.fits')[0]\n",
    "WR_coords = SkyCoord('19h11m30.992s', '+16d51m37.29s', frame='icrs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data_overscan(hdu):\n",
    "    \"\"\"\n",
    "    Search through the image header and return python indices\n",
    "    for where the overscan region is\n",
    "    \n",
    "    Parameters\n",
    "    ---------\n",
    "    hdu : `~astropy.io.fits.hdu.image.PrimaryHDU`\n",
    "        HDU object containing the raw FITS image from which overscan and data arrays \n",
    "        are generated.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    data : `~numpy.ndarray`\n",
    "        Trimmed data\n",
    "    overscan : `~numpy.ndarray`\n",
    "        Overscan region\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    #Give me the overscan and the header\n",
    "    image = hdu.data\n",
    "    header = hdu.header\n",
    "    \n",
    "    #Some string manipulation to get the actual values.\n",
    "    overscan_str = hdu.header['BSEC11'].lstrip('[').rstrip(']').split(',')\n",
    "    data_str = hdu.header['DSEC11'].lstrip('[').rstrip(']').split(',')\n",
    "    overscan_x_min,overscan_x_max = overscan_str[1].split(':')\n",
    "    overscan_y_min,overscan_y_max = overscan_str[0].split(':')\n",
    "    data_x_min,data_x_max = data_str[1].split(':')\n",
    "    data_y_min,data_y_max = data_str[0].split(':')\n",
    "    \n",
    "    #Remember, FITS is 1-indexed, and sections are inclusive,\n",
    "    #whereas python is 0-indexed, and exlusive to the end of a section\n",
    "    data = image[int(data_x_min)-1:int(data_x_max),int(data_y_min)-1:int(data_y_max)]\n",
    "    overscan = image[int(overscan_x_min)-1:int(overscan_x_max),int(overscan_y_min)-1:int(overscan_y_max)]\n",
    "    \n",
    "    return data, overscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trim_subtract_overscan(hdu,fit_degree = 8):\n",
    "    \"\"\"\n",
    "    Search through the image header and return python indices\n",
    "    for where the overscan region is\n",
    "    \n",
    "    Parameters\n",
    "    ---------\n",
    "    hdu : `~astropy.io.fits.hdu.image.PrimaryHDU`\n",
    "        HDU object containing the raw FITS image from which overscan is trimmed, then\n",
    "        fit and subtracted\n",
    "    fit_degree: int, optional\n",
    "        Order of the polynomial used to fit the overscan\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    data_subtracted : `~numpy.ndarray`\n",
    "        Trimmed and overscan-subtracted data\n",
    "    header : `~astropy.io.fits.header.Header`\n",
    "        `~astropy.io.fits.header.Header` object of original fits file,\n",
    "        modified to say the data have been trimmed and overscan subtracted\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    #Trim data\n",
    "    data,overscan = split_data_overscan(hdu)\n",
    "    header = hdu.header\n",
    "    \n",
    "    #Average along columns\n",
    "    avg_overscan = np.mean(overscan,axis=1)\n",
    "    \n",
    "    #Index array, then fit!\n",
    "    idx = np.arange(len(avg_overscan))\n",
    "    p = np.polyfit(idx,avg_overscan,deg=fit_degree)\n",
    "    #Calculate array from fit, then transpose into a column\n",
    "    fit_overscan = np.poly1d(p)(idx)\n",
    "    fit_overscan_col = fit_overscan[:,np.newaxis]\n",
    "    #Subtract column!\n",
    "    data_subtracted = data - fit_overscan_col\n",
    "    \n",
    "    #Edit the header\n",
    "    header.set('COMMENT','Overscan Subtracted + Trimmed')\n",
    "    header.set('COMMENT','Overscan Fit Order = {0}'.format(fit_degree))\n",
    "    \n",
    "    return data_subtracted,header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def master_bias(biaslist,overscan_fit_degree = 8, caldir = None, overwrite = False):\n",
    "    \"\"\"\n",
    "    Construct a master bias using median combination\n",
    "    \n",
    "    Parameters\n",
    "    ---------\n",
    "    biaslist : list\n",
    "        List of filenames, should be complete filenames. Use glob to construct. \n",
    "        If the list is empty, nothing will happen\n",
    "    overscan_fit_degree : int, optional\n",
    "        Order of polynomial to fit overscan with\n",
    "    caldir : str, optional\n",
    "        Directory to place master bias into.\n",
    "    overwrite : bool, optional\n",
    "        If True, and caldir/master_bias.fits exists, it will be overwritten\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    masterbias : `~numpy.ndarray`\n",
    "        Bias array. Note: this will be saved as outdir/master_bias.fits\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    if len(biaslist) == 0:\n",
    "        print('feed me biases!')\n",
    "        return None\n",
    "    \n",
    "    master_biases =[]\n",
    "    for bias_name in biaslist:\n",
    "        hdu = fits.open(bias_name)[0]\n",
    "        data,header = trim_subtract_overscan(hdu,fit_degree=overscan_fit_degree)\n",
    "        master_biases.append(data)\n",
    "        \n",
    "    master_biases = np.array(master_biases)\n",
    "    master_bias = np.median(master_biases,axis=0)\n",
    "    header.set('COMMENT','Biases median-combined')\n",
    "    header.set('COMMENT','Composed of raw bias frames:')\n",
    "    for bias_name in biaslist:\n",
    "        header.set('COMMENT',bias_name)\n",
    "        \n",
    "    bias_hdu = fits.PrimaryHDU(master_bias,header)\n",
    "    if caldir == None:\n",
    "        bias_hdu.writeto('master_bias.fits', overwrite=overwrite)\n",
    "    else:\n",
    "        bias_hdu.writeto(caldir+'master_bias.fits', overwrite=overwrite)\n",
    "        \n",
    "    print('Master bias constructed')\n",
    "    \n",
    "    return master_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def master_dark(darklist,exptime,overscan_fit_degree = 8, caldir = None, overwrite = False):\n",
    "    \"\"\"\n",
    "    Construct a master dark frame using median combination\n",
    "    \n",
    "    Parameters\n",
    "    ---------\n",
    "    darklist : list\n",
    "        List of filenames, should be complete filenames. Use glob to construct. \n",
    "        If the list is empty, nothing will happen\n",
    "    exptime : float\n",
    "        float of exposure time for the dark in seconds. Will be appended to the filename\n",
    "    overscan_fit_degree : int, optional\n",
    "        Order of polynomial to fit overscan with\n",
    "    caldir : str, optional\n",
    "        Directory to place master dark into.\n",
    "    overwrite : bool, optional\n",
    "        If True, and caldir/master_dark_exptime.fits exists, it will be overwritten\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    masterdark : `~numpy.ndarray`\n",
    "        dark array. Note: this will be saved as outdir/master_dark_exptime.fits\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    if len(darklist) == 0:\n",
    "        print('feed me darks!')\n",
    "        return None\n",
    "    \n",
    "    if caldir == None:\n",
    "        bias = fits.getdata('master_bias.fits')\n",
    "    else:\n",
    "        bias = fits.getdata(caldir+'master_bias.fits')\n",
    "        \n",
    "    master_darks = []\n",
    "    for dark_name in darklist:\n",
    "        hdu = fits.open(dark_name)[0]\n",
    "        data,header = trim_subtract_overscan(hdu,fit_degree=overscan_fit_degree)\n",
    "        data -= bias\n",
    "        master_darks.append(data)\n",
    "        \n",
    "    master_darks = np.array(master_darks)\n",
    "    master_dark = np.median(master_darks,axis=0)\n",
    "    \n",
    "    #Some bookkeeping\n",
    "    header.set('COMMENT','Darks median-combined')\n",
    "    header.set('COMMENT','Composed of raw dark frames:')    \n",
    "    for dark_name in darklist:\n",
    "        header.set('COMMENT',dark_name)\n",
    "    if caldir == None:\n",
    "        header.set('COMMENT', 'Bias subtraction done with master_bias.fits')\n",
    "    else:\n",
    "        header.set('COMMENT', 'Bias subtraction done with {0}master_bias.fits'.format(caldir))\n",
    "        \n",
    "    dark_hdu = fits.PrimaryHDU(master_dark,header)\n",
    "    if caldir == None:\n",
    "        dark_hdu.writeto('master_dark_{0}.fits'.format(exptime), overwrite=overwrite)\n",
    "    else:\n",
    "        dark_hdu.writeto(caldir+'master_dark_{0}.fits'.format(exptime), overwrite=overwrite)\n",
    "        \n",
    "    print('Master dark for {0}s constructed'.format(exptime))\n",
    "    \n",
    "    return master_dark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dark(exptime,caldir = None):\n",
    "    \"\"\"\n",
    "    Fetch the appropriate dark frame! If it doesn't exist, scale the longest dark\n",
    "    \n",
    "    Parameters\n",
    "    ---------\n",
    "    exptime : str\n",
    "        float of exposure time for the bias in seconds. Will be appended to the filename\n",
    "    caldir : str, optional\n",
    "       Directory to search for master dark. \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dark : `~np.ndarray`\n",
    "        master dark array.\n",
    "    darkname : str\n",
    "        name of the file for later reference\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    #Search for all possible dark frames\n",
    "    available_darks = glob(caldir+'master_dark*')\n",
    "    available_times = []\n",
    "    #Check the exposure time. If any match, use that dark.\n",
    "    for darkname in available_darks:\n",
    "        dark_hdu = fits.open(darkname)[0]\n",
    "        dark_time = dark_hdu.header['EXPTIME']\n",
    "        available_times.append(dark_time)\n",
    "        if exptime == dark_time:\n",
    "            dark = dark_hdu.data\n",
    "            return dark,darkname\n",
    "        \n",
    "    #If we're here, then no darks with matching exposure times were found. Scale the longest \n",
    "    #dark down to the given exposure time!\n",
    "    #Find the index with the longest time, grab that time and the corresponding dark frame\n",
    "    max_dark_idx = np.argmax(available_times)\n",
    "    max_dark_time = available_times[max_dark_idx]\n",
    "    darkname = available_darks[max_dark_idx]\n",
    "    long_dark = fits.getdata(darkname)\n",
    "    #Scale to the exposure time!\n",
    "    dark = long_dark * exptime / max_dark_time\n",
    "    return dark,darkname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def master_flat(flatlist,filt,overscan_fit_degree = 8, caldir = None, overwrite = False):\n",
    "    \"\"\"\n",
    "    Construct a master flat using median combination\n",
    "    \n",
    "    Parameters\n",
    "    ---------\n",
    "    flatlist : list\n",
    "        List of filenames, should be complete filenames. Use glob to construct. \n",
    "        If the list is empty, nothing will happen\n",
    "    filt : str\n",
    "        Name of filter that you're constructing a flat field for.\n",
    "    overscan_fit_degree : int, optional\n",
    "        Order of polynomial to fit overscan with\n",
    "    caldir : str, optional\n",
    "        Directory to place master dark into.\n",
    "    overwrite : bool, optional\n",
    "        If True, and caldir/master_dark_exptime.fits exists, it will be overwritten\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    masterdark : `~numpy.ndarray`\n",
    "        dark array. Note: this will be saved as outdir/master_dark_exptime.fits\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    if len(flatlist) == 0:\n",
    "        print('feed me flats!')\n",
    "        return None\n",
    "    \n",
    "    if caldir == None:\n",
    "        bias = fits.getdata('master_bias.fits')\n",
    "    else:\n",
    "        bias = fits.getdata(caldir+'master_bias.fits')\n",
    "        \n",
    "    master_flats = []\n",
    "    for flat_name in flatlist:\n",
    "        hdu = fits.open(flat_name)[0]\n",
    "        data,header = trim_subtract_overscan(hdu,fit_degree=overscan_fit_degree)\n",
    "        flat_exptime = hdu.header['EXPTIME']\n",
    "        dark,darkname = get_dark(flat_exptime, caldir = caldir)\n",
    "        data -= bias\n",
    "        data -= dark\n",
    "        master_flats.append(data)\n",
    "        \n",
    "    master_flats = np.array(master_flats)\n",
    "    master_flat = np.median(master_flats,axis=0)\n",
    "    master_flat /= np.max(master_flat)\n",
    "    \n",
    "    #Some bookkeeping\n",
    "    header.set('COMMENT','Flats median-combined')\n",
    "    header.set('COMMENT','Composed of raw flat frames:')\n",
    "    for flat_name in flatlist:\n",
    "        header.set('COMMENT',flat_name)\n",
    "    if caldir == None:\n",
    "        header.set('COMMENT', 'Bias subtraction done with master_bias.fits')\n",
    "    else:\n",
    "        header.set('COMMENT', 'Bias subtraction done with {0}master_bias.fits'.format(caldir))\n",
    "    header.set('COMMENT', 'Dark subtraction done with {0}'.format(darkname))\n",
    "        \n",
    "    flat_hdu = fits.PrimaryHDU(master_flat,header)\n",
    "    if caldir == None:\n",
    "        flat_hdu.writeto('master_flat_{0}.fits'.format(filt), overwrite=overwrite)\n",
    "    else:\n",
    "        flat_hdu.writeto(caldir+'master_flat_{0}.fits'.format(filt), overwrite=overwrite)\n",
    "        \n",
    "    print('Master flat for {0} filter constructed'.format(filt))\n",
    "    \n",
    "    return master_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_flat(hdu,caldir = None):\n",
    "    \"\"\"\n",
    "    Fetch the appropriate master flat! If it doesn't exist, return 1.0\n",
    "    \n",
    "    Parameters\n",
    "    ---------\n",
    "    hdu : `~astropy.io.fits.hdu.image.PrimaryHDU`\n",
    "        `~astropy.io.fits.hdu.image.PrimaryHDU` to find a flat for\n",
    "    caldir : str, optional\n",
    "       Directory to search for master flat. \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    flat : `~np.ndarray`\n",
    "        master flat array.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    our_filt = hdu.header['FILTER']\n",
    "    #Search for all possible dark frames\n",
    "    available_flats = glob(caldir+'master_flat*')\n",
    "    #Check the filter. If any match, use that dark.\n",
    "    for flatname in available_flats:\n",
    "        flat_hdu = fits.open(flatname)[0]\n",
    "        flat_filt = flat_hdu.header['FILTER']\n",
    "        if our_filt == flat_filt:\n",
    "            flat = flat_hdu.data\n",
    "            return flat,flatname\n",
    "        \n",
    "    #If we're here, then no matching master flats with the same filter were found.\n",
    "    print('No flat for {0} found! Setting flat = 1'.format(hdu.header['FILENAME']))\n",
    "    flat = 1.0\n",
    "    flatname = 'NONE FOUND'\n",
    "    return flat,flatname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reduce_science(sciencelist,overscan_fit_degree = 8, caldir = None, reddir = None, overwrite = False, out_pref = 'red_'):\n",
    "    \"\"\"\n",
    "    Reduce the science!\n",
    "    \n",
    "    Parameters\n",
    "    ---------\n",
    "    sciencelist : list\n",
    "        list of filenames to reduce!\n",
    "    overscan_fit_degree : int, optional\n",
    "        Order of polynomial to fit overscan with\n",
    "    caldir : str, optional\n",
    "        Directory to place master dark into.\n",
    "    reddir : str, optional\n",
    "        Directory to place reduced science image into\n",
    "    overwrite : bool, optional\n",
    "        If True, and reddir/master_dark_exptime.fits exists, it will be overwritten\n",
    "    out_pref : str, optional\n",
    "        Appends this string to the beginning of the filename\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    reduced_hdu : `~astropy.io.fits.hdu.image.PrimaryHDU`\n",
    "        Reduced hdu.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    print('Reducing {0} science frames!'.format(len(sciencelist)))\n",
    "    for filename in sciencelist:\n",
    "    \n",
    "        #Read data\n",
    "        hdu = fits.open(filename)[0]\n",
    "\n",
    "        #Trim and subtract overscan\n",
    "        data,header = trim_subtract_overscan(hdu,fit_degree=overscan_fit_degree)\n",
    "\n",
    "        #Bias subtract!\n",
    "        if caldir == None:\n",
    "            bias = fits.getdata('master_bias.fits')\n",
    "            header.set('COMMENT', 'Bias subtraction done with master_bias.fits')\n",
    "        else:\n",
    "            bias = fits.getdata(caldir+'master_bias.fits')\n",
    "            header.set('COMMENT', 'Bias subtraction done with {0}master_bias.fits'.format(caldir))\n",
    "\n",
    "        data -= bias\n",
    "\n",
    "        #Dark subtract!!\n",
    "        exptime = header['EXPTIME']\n",
    "        dark,darkname = get_dark(exptime, caldir=caldir)\n",
    "        header.set('COMMENT', 'Dark subtraction done with {0}'.format(darkname))\n",
    "\n",
    "        data -= dark\n",
    "\n",
    "        #Flat field!\n",
    "        flat,flatname = get_flat(hdu, caldir=caldir)\n",
    "        header.set('COMMENT', 'Flat fielding done with {0}'.format(flatname))\n",
    "\n",
    "        data /= flat\n",
    "\n",
    "        #Mess with some filename stuff so it saves to the right place...\n",
    "        just_filename = filename.split('/')[-1]\n",
    "        if reddir == None:\n",
    "            outname = out_pref+just_filename\n",
    "        else:\n",
    "            outname = reddir+out_pref+just_filename\n",
    "\n",
    "        reduced_hdu = fits.PrimaryHDU(data,header)\n",
    "        reduced_hdu.writeto(outname,overwrite=overwrite)\n",
    "    \n",
    "    return 'Complete!! Hooray!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_lists(datadir = './',bias_keyword = 'Bias', dark_keyword = 'Dark', flat_keyword = 'Flat', science_keyword = 'Object'):\n",
    "    \"\"\"\n",
    "    Generates lists of filetypes to feed into the pipeline\n",
    "    \n",
    "    Parameters\n",
    "    ---------\n",
    "    datadir : str, optional\n",
    "        Directory where the data are stored. Should end in /\n",
    "    bias_keyword : str, optional\n",
    "        How are bias files named?\n",
    "    dark_keyword : str, optional\n",
    "        How are dark files named?\n",
    "    flat_keyword : str, optional\n",
    "        How are flat files named?\n",
    "    science_keyword : str, optional\n",
    "        How are science files named?\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    biaslist : list\n",
    "        list of biases\n",
    "    darklists : list\n",
    "        list of lists of darks, one list for each dark exposure time taken\n",
    "    exptimes : list\n",
    "        list of exposures times, one for each list of darks in darklists\n",
    "    flatlists : list\n",
    "        list of lists of flats, one for each filter taken\n",
    "    filters : list\n",
    "        list of filter names, one for each list of flats in flatlists. Note: because filter\n",
    "        names are messy, this just uses the last letter of the filter. So SDSS g -> g, but \n",
    "        CU Ha -> a. Sorry...\n",
    "    sciencelist :\n",
    "        list of science images\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    files = glob(datadir+'*.fits')\n",
    "    \n",
    "    biaslist = []\n",
    "    tmp_darklist = []\n",
    "    dark_times = []\n",
    "    tmp_flatlist = []\n",
    "    flat_filts = []\n",
    "    sciencelist = []\n",
    "    \n",
    "    #sort by file type \n",
    "    for file in files:\n",
    "        hdu = fits.open(file)[0]\n",
    "        filetype = hdu.header['IMAGETYP']\n",
    "        \n",
    "        if filetype == bias_keyword:\n",
    "            biaslist.append(file)\n",
    "            \n",
    "        elif filetype == dark_keyword:\n",
    "            tmp_darklist.append(file)\n",
    "            exptime = hdu.header['EXPTIME']\n",
    "            dark_times.append(exptime)\n",
    "            \n",
    "        elif filetype == flat_keyword:\n",
    "            tmp_flatlist.append(file)\n",
    "            filt = hdu.header['FILTER']\n",
    "            flat_filts.append(filt)\n",
    "            \n",
    "        elif filetype == science_keyword:\n",
    "            sciencelist.append(file)\n",
    "            \n",
    "    #now sort darks by exptime and flats by filter\n",
    "    darklists = []\n",
    "    exptimes = []\n",
    "    for dark_time in np.unique(dark_times):\n",
    "        darklist = np.array(tmp_darklist)[(dark_times == dark_time)]\n",
    "        darklists.append(list(darklist))\n",
    "        exptimes.append(dark_time)\n",
    "        \n",
    "    flatlists = []\n",
    "    filters = []\n",
    "    for filt in np.unique(flat_filts):\n",
    "        flatlist = np.array(tmp_flatlist)[np.array(flat_filts) == filt]\n",
    "        flatlists.append(list(flatlist))\n",
    "        filters.append(filt[-1])\n",
    "        \n",
    "    return biaslist,darklists,exptimes,flatlists,filters,sciencelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline_run(datadir = './', caldir = None, reddir = None,overscan_fit_degree = 8, overwrite = True, out_pref = 'red_'):\n",
    "    \"\"\"\n",
    "    Runs the entire pipeline. Overscan subtract, trim, bias, dark, flat, you name it.\n",
    "    \n",
    "    Parameters\n",
    "    ---------\n",
    "    datadir : str, optional\n",
    "        Directory where the data are stored. Should end in /\n",
    "    caldir : str, optional\n",
    "        Directory where the master calibration data should go. \n",
    "    reddir : str,optional\n",
    "        Directory where reduced data should go.\n",
    "    overscan_fit_degree : int, optional\n",
    "        Order of polynomial used to fit overscan region.\n",
    "    overwrite : bool, optional\n",
    "        If output files exist already and overwrite = True, overwrites files. Otherwise, exits\n",
    "        with an error\n",
    "    out_pref : str, optional\n",
    "        String attached to filenames of reduced science data\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    biaslist : list\n",
    "        list of biases\n",
    "    darklists : list\n",
    "        list of lists of darks, one list for each dark exposure time taken\n",
    "    exptimes : list\n",
    "        list of exposures times, one for each list of darks in darklists\n",
    "    flatlists : list\n",
    "        list of lists of flats, one for each filter taken\n",
    "    filters : list\n",
    "        list of filter names, one for each list of flats in flatlists. Note: because filter\n",
    "        names are messy, this just uses the last letter of the filter. So SDSS g -> g, but \n",
    "        CU Ha -> a. Sorry...\n",
    "    sciencelist :\n",
    "        list of science images\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    biaslist,darklists,exptimes,flatlists,filters,sciencelist = generate_lists(datadir=datadir)\n",
    "    \n",
    "    if caldir != None:\n",
    "        if not os.path.isdir(caldir):\n",
    "            os.makedirs(caldir)\n",
    "            \n",
    "    if reddir != None:\n",
    "        if not os.path.isdir(reddir):\n",
    "            os.makedirs(reddir)\n",
    "    \n",
    "    print('Making Biases...')\n",
    "    master_bias(biaslist=biaslist,overscan_fit_degree=overscan_fit_degree,caldir=caldir,overwrite=overwrite)\n",
    "    \n",
    "    print('Making Darks...')\n",
    "    for darklist,exptime in zip(darklists,exptimes):\n",
    "        master_dark(darklist=darklist,exptime=exptime,overscan_fit_degree=overscan_fit_degree,caldir=caldir,overwrite=overwrite)\n",
    "    \n",
    "    print('Making Flats')\n",
    "    for flatlist,filt in zip(flatlists,filters):\n",
    "        master_flat(flatlist=flatlist,filt=filt,overscan_fit_degree=overscan_fit_degree,caldir=caldir,overwrite=overwrite)\n",
    "    \n",
    "    print('Reducing Science!')\n",
    "    reduce_science(sciencelis=sciencelist,overscan_fit_degree=overscan_fit_degree,caldir=caldir,reddir=reddir,overwrite=overwrite,out_pref=out_pref)\n",
    "    \n",
    "    return 'Complete!!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making Biases...\n",
      "Master bias constructed\n",
      "Making Darks...\n",
      "Master dark for 10.0s constructed\n",
      "Master dark for 30.0s constructed\n",
      "Making Flats\n",
      "Master flat for a filter constructed\n",
      "Master flat for g filter constructed\n",
      "Master flat for i filter constructed\n",
      "Master flat for r filter constructed\n",
      "Reducing Science!\n",
      "Reducing 81 science frames!\n",
      "No flat for WR124_NII.0090.fits found! Setting flat = 1\n",
      "No flat for WR124_NII.0091.fits found! Setting flat = 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Complete!!'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_pipeline_run(datadir = data_dir,caldir = data_dir+'temp_reduction/',reddir = data_dir+'temp_reduction/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "caldir = reddir = data_dir+'temp_reduction/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making Biases...\n",
      "Master bias constructed\n",
      "Making Darks...\n",
      "Master dark for 10.0s constructed\n",
      "Master dark for 30.0s constructed\n",
      "Making Flats\n",
      "Master flat for a filter constructed\n",
      "Master flat for g filter constructed\n",
      "Master flat for i filter constructed\n",
      "Master flat for r filter constructed\n",
      "Reducing Science!\n",
      "Traceback (most recent call last):\n",
      "  File \"adapt.py\", line 596, in <module>\n",
      "    run_pipeline_run(datadir=datadir,caldir=caldir,reddir=reddir)\n",
      "  File \"adapt.py\", line 578, in run_pipeline_run\n",
      "    reduce_science(sciencelis=sciencelist,overscan_fit_degree=overscan_fit_degree,caldir=caldir,reddir=reddir,overwrite=overwrite,out_pref=out_pref)\n",
      "TypeError: reduce_science() got an unexpected keyword argument 'sciencelis'\n"
     ]
    }
   ],
   "source": [
    "!python adapt.py $data_dir $caldir $reddir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
